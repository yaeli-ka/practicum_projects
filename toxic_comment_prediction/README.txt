"Wikishop" project

The online store "Wikishop" is launching a new service. Now, users can edit and enhance product descriptions, just like in wiki communities. This means that customers can propose their own edits and comment on others' changes. The store needs a tool that will detect toxic comments and send them for moderation.

We need to train a model to classify comments as positive or negative. We have a dataset with labels indicating the toxicity of edits.

We'll build a model with an F1 score of at least 0.75.

Project Steps:
1. Load and prepare the data.
2. Train different models.
3. Draw conclusions.

Data Description:
The data is located in the file toxic_comments.csv.
* The text column contains the text of the comment.
* The toxic column is the target feature.





