{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Знакомство-с-данными-и-анализ\" data-toc-modified-id=\"Знакомство-с-данными-и-анализ-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Знакомство с данными и анализ</a></span></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Модель-логистической-регрессии\" data-toc-modified-id=\"Модель-логистической-регрессии-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Модель логистической регрессии</a></span></li><li><span><a href=\"#Модель-KNeighborsClassifier\" data-toc-modified-id=\"Модель-KNeighborsClassifier-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Модель KNeighborsClassifier</a></span></li><li><span><a href=\"#Модель-CatBoost\" data-toc-modified-id=\"Модель-CatBoost-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Модель CatBoost</a></span></li><li><span><a href=\"#Анализ-лучшей-модели\" data-toc-modified-id=\"Анализ-лучшей-модели-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Анализ лучшей модели</a></span></li><li><span><a href=\"#Тестирование-лучшей-модели\" data-toc-modified-id=\"Тестирование-лучшей-модели-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Тестирование лучшей модели</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Нам предстоит обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Ход выполнения проекта**\n",
    "\n",
    "1. Загрузим и подготовим данные.\n",
    "2. Обучим разные модели. \n",
    "3. Сделаем выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`.\n",
    "* Столбец *text* содержит текст комментария\n",
    "* Столбец *toxic* — целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "en-core-web-sm 3.2.0 requires spacy<3.3.0,>=3.2.0, but you have spacy 3.7.3 which is incompatible.\u001b[0m\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.9/site-packages (from en-core-web-sm==3.7.1) (3.7.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.25.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.61.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.8.2)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.21.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.10.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (49.6.0.post20210108)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.6.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.0.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.9/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en-core-web-sm 3.2.0\n",
      "    Uninstalling en-core-web-sm-3.2.0:\n",
      "      Successfully uninstalled en-core-web-sm-3.2.0\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# установим недостающие библиотеки\n",
    "\n",
    "!pip install -U spacy -q # -q убирает необязательные выводы в командах Linux\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим необходимые библиотеки:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import en_core_web_sm\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") # скроем предупреждения перед финальным запуском тетрадки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Знакомство с данными и анализ\n",
    "Загрузим данные и ознакомимся с ними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv', index_col=[0])\n",
    "df_copy = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение целевого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['toxic'].value_counts().plot(kind='pie', ylabel='Токсичные комментарии', \n",
    "                                autopct='%1.2f%%', title='Распределение целевого признака')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете 159292 комментария. Из них 10.16% негативные, 89.84% позитивные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных\n",
    "Очистим текст от лишних слов, используя регулярные выражения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text).lower()\n",
    "    text = text.split()\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31055</th>\n",
       "      <td>Sometime back, I just happened to log on to ww...</td>\n",
       "      <td>sometime back i just happened to log on to www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102929</th>\n",
       "      <td>\"\\n\\nThe latest edit is much better, don't mak...</td>\n",
       "      <td>the latest edit is much better don t make this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67385</th>\n",
       "      <td>\" October 2007 (UTC)\\n\\nI would think you'd be...</td>\n",
       "      <td>october utc i would think you d be able to get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81167</th>\n",
       "      <td>Thanks for the tip on the currency translation...</td>\n",
       "      <td>thanks for the tip on the currency translation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90182</th>\n",
       "      <td>I would argue that if content on the Con in co...</td>\n",
       "      <td>i would argue that if content on the con in co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "31055   Sometime back, I just happened to log on to ww...   \n",
       "102929  \"\\n\\nThe latest edit is much better, don't mak...   \n",
       "67385   \" October 2007 (UTC)\\n\\nI would think you'd be...   \n",
       "81167   Thanks for the tip on the currency translation...   \n",
       "90182   I would argue that if content on the Con in co...   \n",
       "\n",
       "                                               text_clean  \n",
       "31055   sometime back i just happened to log on to www...  \n",
       "102929  the latest edit is much better don t make this...  \n",
       "67385   october utc i would think you d be able to get...  \n",
       "81167   thanks for the tip on the currency translation...  \n",
       "90182   i would argue that if content on the con in co...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_clean'] = df['text'].apply(clear_text)\n",
    "df[['text', 'text_clean']].sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем текст, используя spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "def lemmatize(text):\n",
    "    temp = []\n",
    "    for token in nlp(text):\n",
    "        if token.is_stop == False:\n",
    "            temp.append(token.lemma_)\n",
    "    return \" \".join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159292/159292 [37:00<00:00, 71.74it/s] \n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['text_lemma'] = df['text_clean'].progress_apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31055</th>\n",
       "      <td>Sometime back, I just happened to log on to ww...</td>\n",
       "      <td>sometime back i just happened to log on to www...</td>\n",
       "      <td>happen log www izoom friend s reference amazed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102929</th>\n",
       "      <td>\"\\n\\nThe latest edit is much better, don't mak...</td>\n",
       "      <td>the latest edit is much better don t make this...</td>\n",
       "      <td>late edit well don t article state super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67385</th>\n",
       "      <td>\" October 2007 (UTC)\\n\\nI would think you'd be...</td>\n",
       "      <td>october utc i would think you d be able to get...</td>\n",
       "      <td>october utc think d able point immune objectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81167</th>\n",
       "      <td>Thanks for the tip on the currency translation...</td>\n",
       "      <td>thanks for the tip on the currency translation...</td>\n",
       "      <td>thank tip currency translation think s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90182</th>\n",
       "      <td>I would argue that if content on the Con in co...</td>\n",
       "      <td>i would argue that if content on the con in co...</td>\n",
       "      <td>argue content con comparison art music proport...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "31055   Sometime back, I just happened to log on to ww...   \n",
       "102929  \"\\n\\nThe latest edit is much better, don't mak...   \n",
       "67385   \" October 2007 (UTC)\\n\\nI would think you'd be...   \n",
       "81167   Thanks for the tip on the currency translation...   \n",
       "90182   I would argue that if content on the Con in co...   \n",
       "\n",
       "                                               text_clean  \\\n",
       "31055   sometime back i just happened to log on to www...   \n",
       "102929  the latest edit is much better don t make this...   \n",
       "67385   october utc i would think you d be able to get...   \n",
       "81167   thanks for the tip on the currency translation...   \n",
       "90182   i would argue that if content on the con in co...   \n",
       "\n",
       "                                               text_lemma  \n",
       "31055   happen log www izoom friend s reference amazed...  \n",
       "102929           late edit well don t article state super  \n",
       "67385   october utc think d able point immune objectio...  \n",
       "81167              thank tip currency translation think s  \n",
       "90182   argue content con comparison art music proport...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text', 'text_clean', 'text_lemma']].sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обозначим константы\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разобьем данные на тренировочные и тестовые\n",
    "train, test = train_test_split(df, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "X_train = train['text_lemma']\n",
    "y_train = train['toxic']\n",
    "X_test = test['text_lemma']\n",
    "y_test = test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем TF-IDF векторизацию и удалим стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "stopwords=list(stopwords)\n",
    " \n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf_model = count_tf_idf.fit(X_train)\n",
    "train_tfidf = count_tf_idf.transform(X_train)\n",
    "test_tfidf = count_tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочного датасета: (119469, 126999)\n",
      "Размер тестового датасета: (39823, 126999)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Размер тренировочного датасета: {train_tfidf.shape}\")\n",
    "print(f\"Размер тестового датасета: {test_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "В датасете 159292 комментария. Из них 10.16% негативные, 89.84% позитивные.\n",
    "\n",
    "Мы провели следующую подготовку данных:\n",
    "* Удалили из текста лищние символы (пунктуация, лишние пробелы)\n",
    "* Провели лемматизацию слов с помощью SpaCy\n",
    "* Удалили стоп-слова\n",
    "* Провели векторизацию корпусов с помощью TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "Обучим разные модели и выберем лучшую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                random_state=42),\n",
       "                   n_jobs=-1, param_distributions={'max_iter': [500, 1000]},\n",
       "                   random_state=42, scoring='f1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# инициализируем модель\n",
    "log_model = LogisticRegression(random_state=RANDOM_STATE, class_weight='balanced')\n",
    "\n",
    "# создаём словарь со значениями гиперпараметров для перебора\n",
    "log_parameters = {\n",
    "    'max_iter': [500, 1000]\n",
    "} \n",
    "\n",
    "log_search = RandomizedSearchCV(\n",
    "    log_model,\n",
    "    log_parameters,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "log_search.fit(train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 при кросс-валидации: 0.751\n",
      "Параметры для лучшей модели: {'max_iter': 500}\n"
     ]
    }
   ],
   "source": [
    "log_f1 = np.round(log_search.best_score_, 3)\n",
    "print(f'Метрика F1 при кросс-валидации: {log_f1}')\n",
    "print(f'Параметры для лучшей модели: {log_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'n_neighbors': range(2, 5)},\n",
       "                   random_state=42, scoring='f1')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# инициализируем модель\n",
    "kneighbors_model = KNeighborsClassifier()\n",
    "\n",
    "# создаём словарь со значениями гиперпараметров для перебора\n",
    "kneighbors_parameters = {\n",
    "        'n_neighbors': range(2, 5)\n",
    "    }\n",
    " \n",
    "\n",
    "kneighbors_search = RandomizedSearchCV(\n",
    "    kneighbors_model,\n",
    "    kneighbors_parameters,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "kneighbors_search.fit(train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 при кросс-валидации: 0.307\n",
      "Параметры для лучшей модели: {'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "kneighbors_f1 = np.round(kneighbors_search.best_score_, 3)\n",
    "print(f'Метрика F1 при кросс-валидации: {kneighbors_f1}')\n",
    "print(f'Параметры для лучшей модели: {kneighbors_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3382943\ttotal: 14s\tremaining: 2m 6s\n",
      "1:\tlearn: 0.2464975\ttotal: 27.7s\tremaining: 1m 50s\n",
      "2:\tlearn: 0.2184602\ttotal: 41.7s\tremaining: 1m 37s\n",
      "3:\tlearn: 0.2044095\ttotal: 55.5s\tremaining: 1m 23s\n",
      "4:\tlearn: 0.1952476\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "5:\tlearn: 0.1854749\ttotal: 1m 23s\tremaining: 55.6s\n",
      "6:\tlearn: 0.1803259\ttotal: 1m 37s\tremaining: 41.6s\n",
      "7:\tlearn: 0.1758891\ttotal: 1m 51s\tremaining: 27.8s\n",
      "8:\tlearn: 0.1720860\ttotal: 2m 4s\tremaining: 13.9s\n",
      "9:\tlearn: 0.1689024\ttotal: 2m 18s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3379218\ttotal: 14.4s\tremaining: 2m 9s\n",
      "1:\tlearn: 0.2505130\ttotal: 28.9s\tremaining: 1m 55s\n",
      "2:\tlearn: 0.2184118\ttotal: 43.4s\tremaining: 1m 41s\n",
      "3:\tlearn: 0.2040783\ttotal: 58s\tremaining: 1m 26s\n",
      "4:\tlearn: 0.1945159\ttotal: 1m 12s\tremaining: 1m 12s\n",
      "5:\tlearn: 0.1863840\ttotal: 1m 27s\tremaining: 58.1s\n",
      "6:\tlearn: 0.1813660\ttotal: 1m 41s\tremaining: 43.5s\n",
      "7:\tlearn: 0.1766023\ttotal: 1m 55s\tremaining: 28.9s\n",
      "8:\tlearn: 0.1719474\ttotal: 2m 10s\tremaining: 14.5s\n",
      "9:\tlearn: 0.1685200\ttotal: 2m 24s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3362896\ttotal: 14.1s\tremaining: 2m 7s\n",
      "1:\tlearn: 0.2466539\ttotal: 27.7s\tremaining: 1m 50s\n",
      "2:\tlearn: 0.2201746\ttotal: 41.3s\tremaining: 1m 36s\n",
      "3:\tlearn: 0.2027237\ttotal: 54.7s\tremaining: 1m 22s\n",
      "4:\tlearn: 0.1929550\ttotal: 1m 8s\tremaining: 1m 8s\n",
      "5:\tlearn: 0.1867476\ttotal: 1m 21s\tremaining: 54.6s\n",
      "6:\tlearn: 0.1813855\ttotal: 1m 35s\tremaining: 41s\n",
      "7:\tlearn: 0.1774970\ttotal: 1m 49s\tremaining: 27.3s\n",
      "8:\tlearn: 0.1736757\ttotal: 2m 3s\tremaining: 13.7s\n",
      "9:\tlearn: 0.1698581\ttotal: 2m 16s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3341969\ttotal: 14s\tremaining: 2m 5s\n",
      "1:\tlearn: 0.2466649\ttotal: 28.1s\tremaining: 1m 52s\n",
      "2:\tlearn: 0.2167687\ttotal: 42.1s\tremaining: 1m 38s\n",
      "3:\tlearn: 0.2020520\ttotal: 56.2s\tremaining: 1m 24s\n",
      "4:\tlearn: 0.1930994\ttotal: 1m 10s\tremaining: 1m 10s\n",
      "5:\tlearn: 0.1870084\ttotal: 1m 24s\tremaining: 56.3s\n",
      "6:\tlearn: 0.1807552\ttotal: 1m 38s\tremaining: 42.3s\n",
      "7:\tlearn: 0.1757180\ttotal: 1m 52s\tremaining: 28.2s\n",
      "8:\tlearn: 0.1720252\ttotal: 2m 7s\tremaining: 14.1s\n",
      "9:\tlearn: 0.1688386\ttotal: 2m 21s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3301795\ttotal: 13.8s\tremaining: 2m 3s\n",
      "1:\tlearn: 0.2448223\ttotal: 27.6s\tremaining: 1m 50s\n",
      "2:\tlearn: 0.2146204\ttotal: 41.2s\tremaining: 1m 36s\n",
      "3:\tlearn: 0.2001216\ttotal: 55s\tremaining: 1m 22s\n",
      "4:\tlearn: 0.1914283\ttotal: 1m 8s\tremaining: 1m 8s\n",
      "5:\tlearn: 0.1845098\ttotal: 1m 22s\tremaining: 54.7s\n",
      "6:\tlearn: 0.1785134\ttotal: 1m 35s\tremaining: 41s\n",
      "7:\tlearn: 0.1747217\ttotal: 1m 49s\tremaining: 27.4s\n",
      "8:\tlearn: 0.1712881\ttotal: 2m 3s\tremaining: 13.7s\n",
      "9:\tlearn: 0.1680876\ttotal: 2m 16s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3382943\ttotal: 14.4s\tremaining: 23m 42s\n",
      "1:\tlearn: 0.2464975\ttotal: 28.4s\tremaining: 23m 9s\n",
      "2:\tlearn: 0.2184602\ttotal: 42.6s\tremaining: 22m 55s\n",
      "3:\tlearn: 0.2044095\ttotal: 57s\tremaining: 22m 47s\n",
      "4:\tlearn: 0.1952476\ttotal: 1m 11s\tremaining: 22m 38s\n",
      "5:\tlearn: 0.1854749\ttotal: 1m 25s\tremaining: 22m 23s\n",
      "6:\tlearn: 0.1803259\ttotal: 1m 39s\tremaining: 22m 8s\n",
      "7:\tlearn: 0.1758891\ttotal: 1m 54s\tremaining: 21m 54s\n",
      "8:\tlearn: 0.1720860\ttotal: 2m 8s\tremaining: 21m 43s\n",
      "9:\tlearn: 0.1689024\ttotal: 2m 23s\tremaining: 21m 29s\n",
      "10:\tlearn: 0.1661912\ttotal: 2m 38s\tremaining: 21m 19s\n",
      "11:\tlearn: 0.1633091\ttotal: 2m 52s\tremaining: 21m 5s\n",
      "12:\tlearn: 0.1611252\ttotal: 3m 7s\tremaining: 20m 51s\n",
      "13:\tlearn: 0.1587187\ttotal: 3m 21s\tremaining: 20m 38s\n",
      "14:\tlearn: 0.1565532\ttotal: 3m 36s\tremaining: 20m 25s\n",
      "15:\tlearn: 0.1546255\ttotal: 3m 50s\tremaining: 20m 12s\n",
      "16:\tlearn: 0.1525760\ttotal: 4m 5s\tremaining: 19m 57s\n",
      "17:\tlearn: 0.1511509\ttotal: 4m 19s\tremaining: 19m 43s\n",
      "18:\tlearn: 0.1494658\ttotal: 4m 34s\tremaining: 19m 28s\n",
      "19:\tlearn: 0.1475237\ttotal: 4m 48s\tremaining: 19m 13s\n",
      "20:\tlearn: 0.1457804\ttotal: 5m 3s\tremaining: 18m 59s\n",
      "21:\tlearn: 0.1442061\ttotal: 5m 17s\tremaining: 18m 46s\n",
      "22:\tlearn: 0.1425611\ttotal: 5m 32s\tremaining: 18m 33s\n",
      "23:\tlearn: 0.1413332\ttotal: 5m 47s\tremaining: 18m 19s\n",
      "24:\tlearn: 0.1400864\ttotal: 6m 1s\tremaining: 18m 5s\n",
      "25:\tlearn: 0.1385073\ttotal: 6m 16s\tremaining: 17m 52s\n",
      "26:\tlearn: 0.1373439\ttotal: 6m 31s\tremaining: 17m 37s\n",
      "27:\tlearn: 0.1358349\ttotal: 6m 45s\tremaining: 17m 23s\n",
      "28:\tlearn: 0.1348716\ttotal: 7m\tremaining: 17m 8s\n",
      "29:\tlearn: 0.1336123\ttotal: 7m 14s\tremaining: 16m 54s\n",
      "30:\tlearn: 0.1328671\ttotal: 7m 28s\tremaining: 16m 39s\n",
      "31:\tlearn: 0.1318498\ttotal: 7m 43s\tremaining: 16m 24s\n",
      "32:\tlearn: 0.1312936\ttotal: 7m 57s\tremaining: 16m 10s\n",
      "33:\tlearn: 0.1306715\ttotal: 8m 12s\tremaining: 15m 56s\n",
      "34:\tlearn: 0.1293616\ttotal: 8m 27s\tremaining: 15m 41s\n",
      "35:\tlearn: 0.1281925\ttotal: 8m 41s\tremaining: 15m 26s\n",
      "36:\tlearn: 0.1273880\ttotal: 8m 56s\tremaining: 15m 13s\n",
      "37:\tlearn: 0.1268672\ttotal: 9m 10s\tremaining: 14m 58s\n",
      "38:\tlearn: 0.1261626\ttotal: 9m 25s\tremaining: 14m 44s\n",
      "39:\tlearn: 0.1251183\ttotal: 9m 39s\tremaining: 14m 29s\n",
      "40:\tlearn: 0.1241948\ttotal: 9m 54s\tremaining: 14m 15s\n",
      "41:\tlearn: 0.1233449\ttotal: 10m 8s\tremaining: 14m\n",
      "42:\tlearn: 0.1228941\ttotal: 10m 23s\tremaining: 13m 46s\n",
      "43:\tlearn: 0.1223919\ttotal: 10m 37s\tremaining: 13m 31s\n",
      "44:\tlearn: 0.1216532\ttotal: 10m 52s\tremaining: 13m 17s\n",
      "45:\tlearn: 0.1205375\ttotal: 11m 6s\tremaining: 13m 2s\n",
      "46:\tlearn: 0.1201290\ttotal: 11m 21s\tremaining: 12m 48s\n",
      "47:\tlearn: 0.1194206\ttotal: 11m 36s\tremaining: 12m 34s\n",
      "48:\tlearn: 0.1190443\ttotal: 11m 50s\tremaining: 12m 19s\n",
      "49:\tlearn: 0.1181192\ttotal: 12m 5s\tremaining: 12m 5s\n",
      "50:\tlearn: 0.1175890\ttotal: 12m 19s\tremaining: 11m 50s\n",
      "51:\tlearn: 0.1168909\ttotal: 12m 34s\tremaining: 11m 36s\n",
      "52:\tlearn: 0.1164125\ttotal: 12m 48s\tremaining: 11m 21s\n",
      "53:\tlearn: 0.1160022\ttotal: 13m 2s\tremaining: 11m 6s\n",
      "54:\tlearn: 0.1156258\ttotal: 13m 17s\tremaining: 10m 52s\n",
      "55:\tlearn: 0.1152774\ttotal: 13m 31s\tremaining: 10m 37s\n",
      "56:\tlearn: 0.1149594\ttotal: 13m 45s\tremaining: 10m 22s\n",
      "57:\tlearn: 0.1141131\ttotal: 13m 59s\tremaining: 10m 7s\n",
      "58:\tlearn: 0.1138241\ttotal: 14m 13s\tremaining: 9m 53s\n",
      "59:\tlearn: 0.1131291\ttotal: 14m 28s\tremaining: 9m 38s\n",
      "60:\tlearn: 0.1127879\ttotal: 14m 42s\tremaining: 9m 24s\n",
      "61:\tlearn: 0.1123370\ttotal: 14m 57s\tremaining: 9m 9s\n",
      "62:\tlearn: 0.1118047\ttotal: 15m 11s\tremaining: 8m 55s\n",
      "63:\tlearn: 0.1115338\ttotal: 15m 26s\tremaining: 8m 40s\n",
      "64:\tlearn: 0.1112766\ttotal: 15m 40s\tremaining: 8m 26s\n",
      "65:\tlearn: 0.1107146\ttotal: 15m 54s\tremaining: 8m 11s\n",
      "66:\tlearn: 0.1098443\ttotal: 16m 9s\tremaining: 7m 57s\n",
      "67:\tlearn: 0.1096059\ttotal: 16m 23s\tremaining: 7m 43s\n",
      "68:\tlearn: 0.1093699\ttotal: 16m 38s\tremaining: 7m 28s\n",
      "69:\tlearn: 0.1091405\ttotal: 16m 52s\tremaining: 7m 14s\n",
      "70:\tlearn: 0.1085870\ttotal: 17m 7s\tremaining: 6m 59s\n",
      "71:\tlearn: 0.1082748\ttotal: 17m 21s\tremaining: 6m 45s\n",
      "72:\tlearn: 0.1080475\ttotal: 17m 35s\tremaining: 6m 30s\n",
      "73:\tlearn: 0.1078221\ttotal: 17m 50s\tremaining: 6m 16s\n",
      "74:\tlearn: 0.1076344\ttotal: 18m 5s\tremaining: 6m 1s\n",
      "75:\tlearn: 0.1071008\ttotal: 18m 20s\tremaining: 5m 47s\n",
      "76:\tlearn: 0.1064736\ttotal: 18m 34s\tremaining: 5m 32s\n",
      "77:\tlearn: 0.1061843\ttotal: 18m 48s\tremaining: 5m 18s\n",
      "78:\tlearn: 0.1059759\ttotal: 19m 2s\tremaining: 5m 3s\n",
      "79:\tlearn: 0.1054483\ttotal: 19m 16s\tremaining: 4m 49s\n",
      "80:\tlearn: 0.1052609\ttotal: 19m 31s\tremaining: 4m 34s\n",
      "81:\tlearn: 0.1047206\ttotal: 19m 45s\tremaining: 4m 20s\n",
      "82:\tlearn: 0.1044779\ttotal: 20m\tremaining: 4m 5s\n",
      "83:\tlearn: 0.1042577\ttotal: 20m 14s\tremaining: 3m 51s\n",
      "84:\tlearn: 0.1039697\ttotal: 20m 28s\tremaining: 3m 36s\n",
      "85:\tlearn: 0.1033656\ttotal: 20m 43s\tremaining: 3m 22s\n",
      "86:\tlearn: 0.1031834\ttotal: 20m 57s\tremaining: 3m 7s\n",
      "87:\tlearn: 0.1024739\ttotal: 21m 12s\tremaining: 2m 53s\n",
      "88:\tlearn: 0.1022994\ttotal: 21m 26s\tremaining: 2m 38s\n",
      "89:\tlearn: 0.1018548\ttotal: 21m 40s\tremaining: 2m 24s\n",
      "90:\tlearn: 0.1013924\ttotal: 21m 55s\tremaining: 2m 10s\n",
      "91:\tlearn: 0.1009681\ttotal: 22m 9s\tremaining: 1m 55s\n",
      "92:\tlearn: 0.1005381\ttotal: 22m 23s\tremaining: 1m 41s\n",
      "93:\tlearn: 0.1003773\ttotal: 22m 37s\tremaining: 1m 26s\n",
      "94:\tlearn: 0.0998045\ttotal: 22m 52s\tremaining: 1m 12s\n",
      "95:\tlearn: 0.0995615\ttotal: 23m 6s\tremaining: 57.8s\n",
      "96:\tlearn: 0.0991987\ttotal: 23m 20s\tremaining: 43.3s\n",
      "97:\tlearn: 0.0988924\ttotal: 23m 34s\tremaining: 28.9s\n",
      "98:\tlearn: 0.0984472\ttotal: 23m 48s\tremaining: 14.4s\n",
      "99:\tlearn: 0.0982595\ttotal: 24m 2s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3379218\ttotal: 13.9s\tremaining: 22m 53s\n",
      "1:\tlearn: 0.2505130\ttotal: 27.5s\tremaining: 22m 26s\n",
      "2:\tlearn: 0.2184118\ttotal: 41s\tremaining: 22m 5s\n",
      "3:\tlearn: 0.2040783\ttotal: 54.5s\tremaining: 21m 48s\n",
      "4:\tlearn: 0.1945159\ttotal: 1m 8s\tremaining: 21m 32s\n",
      "5:\tlearn: 0.1863840\ttotal: 1m 21s\tremaining: 21m 16s\n",
      "6:\tlearn: 0.1813660\ttotal: 1m 34s\tremaining: 21m 1s\n",
      "7:\tlearn: 0.1766023\ttotal: 1m 48s\tremaining: 20m 47s\n",
      "8:\tlearn: 0.1719474\ttotal: 2m 1s\tremaining: 20m 33s\n",
      "9:\tlearn: 0.1685200\ttotal: 2m 15s\tremaining: 20m 21s\n",
      "10:\tlearn: 0.1658117\ttotal: 2m 29s\tremaining: 20m 7s\n",
      "11:\tlearn: 0.1627172\ttotal: 2m 42s\tremaining: 19m 53s\n",
      "12:\tlearn: 0.1606511\ttotal: 2m 56s\tremaining: 19m 39s\n",
      "13:\tlearn: 0.1585470\ttotal: 3m 9s\tremaining: 19m 24s\n",
      "14:\tlearn: 0.1567032\ttotal: 3m 23s\tremaining: 19m 10s\n",
      "15:\tlearn: 0.1548660\ttotal: 3m 36s\tremaining: 18m 55s\n",
      "16:\tlearn: 0.1527182\ttotal: 3m 49s\tremaining: 18m 42s\n",
      "17:\tlearn: 0.1507139\ttotal: 4m 3s\tremaining: 18m 29s\n",
      "18:\tlearn: 0.1486091\ttotal: 4m 16s\tremaining: 18m 15s\n",
      "19:\tlearn: 0.1469905\ttotal: 4m 30s\tremaining: 18m 1s\n",
      "20:\tlearn: 0.1453878\ttotal: 4m 44s\tremaining: 17m 49s\n",
      "21:\tlearn: 0.1438006\ttotal: 4m 57s\tremaining: 17m 35s\n",
      "22:\tlearn: 0.1426441\ttotal: 5m 11s\tremaining: 17m 21s\n",
      "23:\tlearn: 0.1415728\ttotal: 5m 24s\tremaining: 17m 8s\n",
      "24:\tlearn: 0.1399665\ttotal: 5m 38s\tremaining: 16m 54s\n",
      "25:\tlearn: 0.1385773\ttotal: 5m 51s\tremaining: 16m 41s\n",
      "26:\tlearn: 0.1371885\ttotal: 6m 5s\tremaining: 16m 28s\n",
      "27:\tlearn: 0.1364670\ttotal: 6m 19s\tremaining: 16m 15s\n",
      "28:\tlearn: 0.1352101\ttotal: 6m 32s\tremaining: 16m 2s\n",
      "29:\tlearn: 0.1340534\ttotal: 6m 46s\tremaining: 15m 48s\n",
      "30:\tlearn: 0.1328741\ttotal: 7m\tremaining: 15m 34s\n",
      "31:\tlearn: 0.1321773\ttotal: 7m 13s\tremaining: 15m 21s\n",
      "32:\tlearn: 0.1313638\ttotal: 7m 27s\tremaining: 15m 8s\n",
      "33:\tlearn: 0.1308587\ttotal: 7m 40s\tremaining: 14m 54s\n",
      "34:\tlearn: 0.1298002\ttotal: 7m 54s\tremaining: 14m 41s\n",
      "35:\tlearn: 0.1292279\ttotal: 8m 8s\tremaining: 14m 27s\n",
      "36:\tlearn: 0.1285388\ttotal: 8m 21s\tremaining: 14m 14s\n",
      "37:\tlearn: 0.1274036\ttotal: 8m 35s\tremaining: 14m 1s\n",
      "38:\tlearn: 0.1262406\ttotal: 8m 49s\tremaining: 13m 47s\n",
      "39:\tlearn: 0.1253421\ttotal: 9m 2s\tremaining: 13m 33s\n",
      "40:\tlearn: 0.1248949\ttotal: 9m 16s\tremaining: 13m 20s\n",
      "41:\tlearn: 0.1241020\ttotal: 9m 30s\tremaining: 13m 7s\n",
      "42:\tlearn: 0.1231046\ttotal: 9m 43s\tremaining: 12m 53s\n",
      "43:\tlearn: 0.1220377\ttotal: 9m 57s\tremaining: 12m 40s\n",
      "44:\tlearn: 0.1213644\ttotal: 10m 10s\tremaining: 12m 26s\n",
      "45:\tlearn: 0.1208596\ttotal: 10m 24s\tremaining: 12m 13s\n",
      "46:\tlearn: 0.1200136\ttotal: 10m 38s\tremaining: 11m 59s\n",
      "47:\tlearn: 0.1196359\ttotal: 10m 52s\tremaining: 11m 46s\n",
      "48:\tlearn: 0.1188444\ttotal: 11m 5s\tremaining: 11m 32s\n",
      "49:\tlearn: 0.1181389\ttotal: 11m 19s\tremaining: 11m 19s\n",
      "50:\tlearn: 0.1177458\ttotal: 11m 33s\tremaining: 11m 5s\n",
      "51:\tlearn: 0.1173817\ttotal: 11m 46s\tremaining: 10m 52s\n",
      "52:\tlearn: 0.1170257\ttotal: 12m\tremaining: 10m 38s\n",
      "53:\tlearn: 0.1164421\ttotal: 12m 14s\tremaining: 10m 25s\n",
      "54:\tlearn: 0.1161069\ttotal: 12m 27s\tremaining: 10m 11s\n",
      "55:\tlearn: 0.1156521\ttotal: 12m 41s\tremaining: 9m 58s\n",
      "56:\tlearn: 0.1153539\ttotal: 12m 55s\tremaining: 9m 45s\n",
      "57:\tlearn: 0.1150488\ttotal: 13m 9s\tremaining: 9m 31s\n",
      "58:\tlearn: 0.1143420\ttotal: 13m 22s\tremaining: 9m 17s\n",
      "59:\tlearn: 0.1140625\ttotal: 13m 36s\tremaining: 9m 4s\n",
      "60:\tlearn: 0.1137728\ttotal: 13m 49s\tremaining: 8m 50s\n",
      "61:\tlearn: 0.1129272\ttotal: 14m 3s\tremaining: 8m 36s\n",
      "62:\tlearn: 0.1125826\ttotal: 14m 17s\tremaining: 8m 23s\n",
      "63:\tlearn: 0.1115686\ttotal: 14m 30s\tremaining: 8m 9s\n",
      "64:\tlearn: 0.1112996\ttotal: 14m 44s\tremaining: 7m 56s\n",
      "65:\tlearn: 0.1105366\ttotal: 14m 58s\tremaining: 7m 42s\n",
      "66:\tlearn: 0.1102643\ttotal: 15m 12s\tremaining: 7m 29s\n",
      "67:\tlearn: 0.1099928\ttotal: 15m 25s\tremaining: 7m 15s\n",
      "68:\tlearn: 0.1095241\ttotal: 15m 39s\tremaining: 7m 2s\n",
      "69:\tlearn: 0.1091512\ttotal: 15m 53s\tremaining: 6m 48s\n",
      "70:\tlearn: 0.1088314\ttotal: 16m 7s\tremaining: 6m 35s\n",
      "71:\tlearn: 0.1082251\ttotal: 16m 21s\tremaining: 6m 21s\n",
      "72:\tlearn: 0.1076270\ttotal: 16m 34s\tremaining: 6m 7s\n",
      "73:\tlearn: 0.1070133\ttotal: 16m 48s\tremaining: 5m 54s\n",
      "74:\tlearn: 0.1062176\ttotal: 17m 2s\tremaining: 5m 40s\n",
      "75:\tlearn: 0.1059910\ttotal: 17m 16s\tremaining: 5m 27s\n",
      "76:\tlearn: 0.1057776\ttotal: 17m 30s\tremaining: 5m 13s\n",
      "77:\tlearn: 0.1054233\ttotal: 17m 43s\tremaining: 5m\n",
      "78:\tlearn: 0.1046852\ttotal: 17m 57s\tremaining: 4m 46s\n",
      "79:\tlearn: 0.1044807\ttotal: 18m 11s\tremaining: 4m 32s\n",
      "80:\tlearn: 0.1037939\ttotal: 18m 24s\tremaining: 4m 19s\n",
      "81:\tlearn: 0.1035889\ttotal: 18m 38s\tremaining: 4m 5s\n",
      "82:\tlearn: 0.1030355\ttotal: 18m 52s\tremaining: 3m 51s\n",
      "83:\tlearn: 0.1028404\ttotal: 19m 6s\tremaining: 3m 38s\n",
      "84:\tlearn: 0.1024021\ttotal: 19m 19s\tremaining: 3m 24s\n",
      "85:\tlearn: 0.1018389\ttotal: 19m 33s\tremaining: 3m 11s\n",
      "86:\tlearn: 0.1015712\ttotal: 19m 47s\tremaining: 2m 57s\n",
      "87:\tlearn: 0.1012650\ttotal: 20m\tremaining: 2m 43s\n",
      "88:\tlearn: 0.1010816\ttotal: 20m 15s\tremaining: 2m 30s\n",
      "89:\tlearn: 0.1006423\ttotal: 20m 28s\tremaining: 2m 16s\n",
      "90:\tlearn: 0.1003511\ttotal: 20m 42s\tremaining: 2m 2s\n",
      "91:\tlearn: 0.1001711\ttotal: 20m 56s\tremaining: 1m 49s\n",
      "92:\tlearn: 0.0999488\ttotal: 21m 10s\tremaining: 1m 35s\n",
      "93:\tlearn: 0.0997718\ttotal: 21m 24s\tremaining: 1m 21s\n",
      "94:\tlearn: 0.0992764\ttotal: 21m 37s\tremaining: 1m 8s\n",
      "95:\tlearn: 0.0990229\ttotal: 21m 51s\tremaining: 54.6s\n",
      "96:\tlearn: 0.0985345\ttotal: 22m 5s\tremaining: 41s\n",
      "97:\tlearn: 0.0983634\ttotal: 22m 19s\tremaining: 27.3s\n",
      "98:\tlearn: 0.0981613\ttotal: 22m 33s\tremaining: 13.7s\n",
      "99:\tlearn: 0.0977910\ttotal: 22m 46s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3362896\ttotal: 14s\tremaining: 23m 3s\n",
      "1:\tlearn: 0.2466539\ttotal: 28.2s\tremaining: 23m 1s\n",
      "2:\tlearn: 0.2201746\ttotal: 42.4s\tremaining: 22m 51s\n",
      "3:\tlearn: 0.2027237\ttotal: 56.6s\tremaining: 22m 38s\n",
      "4:\tlearn: 0.1929550\ttotal: 1m 10s\tremaining: 22m 16s\n",
      "5:\tlearn: 0.1867476\ttotal: 1m 24s\tremaining: 22m\n",
      "6:\tlearn: 0.1813855\ttotal: 1m 38s\tremaining: 21m 46s\n",
      "7:\tlearn: 0.1774970\ttotal: 1m 52s\tremaining: 21m 28s\n",
      "8:\tlearn: 0.1736757\ttotal: 2m 6s\tremaining: 21m 15s\n",
      "9:\tlearn: 0.1698581\ttotal: 2m 19s\tremaining: 20m 59s\n",
      "10:\tlearn: 0.1668704\ttotal: 2m 33s\tremaining: 20m 45s\n",
      "11:\tlearn: 0.1644674\ttotal: 2m 47s\tremaining: 20m 29s\n",
      "12:\tlearn: 0.1613128\ttotal: 3m 1s\tremaining: 20m 13s\n",
      "13:\tlearn: 0.1586573\ttotal: 3m 15s\tremaining: 19m 58s\n",
      "14:\tlearn: 0.1567370\ttotal: 3m 28s\tremaining: 19m 44s\n",
      "15:\tlearn: 0.1549100\ttotal: 3m 42s\tremaining: 19m 30s\n",
      "16:\tlearn: 0.1527873\ttotal: 3m 56s\tremaining: 19m 16s\n",
      "17:\tlearn: 0.1512154\ttotal: 4m 10s\tremaining: 19m 2s\n",
      "18:\tlearn: 0.1488257\ttotal: 4m 24s\tremaining: 18m 47s\n",
      "19:\tlearn: 0.1473505\ttotal: 4m 38s\tremaining: 18m 33s\n",
      "20:\tlearn: 0.1461386\ttotal: 4m 52s\tremaining: 18m 20s\n",
      "21:\tlearn: 0.1447128\ttotal: 5m 6s\tremaining: 18m 6s\n",
      "22:\tlearn: 0.1430888\ttotal: 5m 20s\tremaining: 17m 51s\n",
      "23:\tlearn: 0.1414605\ttotal: 5m 34s\tremaining: 17m 37s\n",
      "24:\tlearn: 0.1403298\ttotal: 5m 48s\tremaining: 17m 24s\n",
      "25:\tlearn: 0.1392697\ttotal: 6m 1s\tremaining: 17m 9s\n",
      "26:\tlearn: 0.1380708\ttotal: 6m 15s\tremaining: 16m 55s\n",
      "27:\tlearn: 0.1368983\ttotal: 6m 29s\tremaining: 16m 41s\n",
      "28:\tlearn: 0.1359191\ttotal: 6m 43s\tremaining: 16m 27s\n",
      "29:\tlearn: 0.1344738\ttotal: 6m 57s\tremaining: 16m 13s\n",
      "30:\tlearn: 0.1336538\ttotal: 7m 11s\tremaining: 15m 59s\n",
      "31:\tlearn: 0.1329731\ttotal: 7m 24s\tremaining: 15m 45s\n",
      "32:\tlearn: 0.1320147\ttotal: 7m 38s\tremaining: 15m 31s\n",
      "33:\tlearn: 0.1310340\ttotal: 7m 52s\tremaining: 15m 17s\n",
      "34:\tlearn: 0.1299143\ttotal: 8m 6s\tremaining: 15m 4s\n",
      "35:\tlearn: 0.1292883\ttotal: 8m 20s\tremaining: 14m 50s\n",
      "36:\tlearn: 0.1280720\ttotal: 8m 34s\tremaining: 14m 36s\n",
      "37:\tlearn: 0.1270766\ttotal: 8m 48s\tremaining: 14m 22s\n",
      "38:\tlearn: 0.1265921\ttotal: 9m 2s\tremaining: 14m 8s\n",
      "39:\tlearn: 0.1253399\ttotal: 9m 16s\tremaining: 13m 54s\n",
      "40:\tlearn: 0.1243564\ttotal: 9m 30s\tremaining: 13m 40s\n",
      "41:\tlearn: 0.1238080\ttotal: 9m 44s\tremaining: 13m 27s\n",
      "42:\tlearn: 0.1233728\ttotal: 9m 58s\tremaining: 13m 13s\n",
      "43:\tlearn: 0.1224683\ttotal: 10m 12s\tremaining: 12m 59s\n",
      "44:\tlearn: 0.1215134\ttotal: 10m 26s\tremaining: 12m 45s\n",
      "45:\tlearn: 0.1211224\ttotal: 10m 40s\tremaining: 12m 32s\n",
      "46:\tlearn: 0.1207367\ttotal: 10m 54s\tremaining: 12m 18s\n",
      "47:\tlearn: 0.1199438\ttotal: 11m 8s\tremaining: 12m 4s\n",
      "48:\tlearn: 0.1193559\ttotal: 11m 22s\tremaining: 11m 50s\n",
      "49:\tlearn: 0.1186297\ttotal: 11m 36s\tremaining: 11m 36s\n",
      "50:\tlearn: 0.1180807\ttotal: 11m 50s\tremaining: 11m 22s\n",
      "51:\tlearn: 0.1177044\ttotal: 12m 4s\tremaining: 11m 8s\n",
      "52:\tlearn: 0.1173478\ttotal: 12m 18s\tremaining: 10m 54s\n",
      "53:\tlearn: 0.1169664\ttotal: 12m 32s\tremaining: 10m 40s\n",
      "54:\tlearn: 0.1161773\ttotal: 12m 46s\tremaining: 10m 26s\n",
      "55:\tlearn: 0.1158573\ttotal: 13m\tremaining: 10m 12s\n",
      "56:\tlearn: 0.1154213\ttotal: 13m 14s\tremaining: 9m 59s\n",
      "57:\tlearn: 0.1151151\ttotal: 13m 27s\tremaining: 9m 45s\n",
      "58:\tlearn: 0.1148228\ttotal: 13m 41s\tremaining: 9m 31s\n",
      "59:\tlearn: 0.1140777\ttotal: 13m 55s\tremaining: 9m 17s\n",
      "60:\tlearn: 0.1138165\ttotal: 14m 9s\tremaining: 9m 3s\n",
      "61:\tlearn: 0.1135270\ttotal: 14m 23s\tremaining: 8m 49s\n",
      "62:\tlearn: 0.1128477\ttotal: 14m 37s\tremaining: 8m 35s\n",
      "63:\tlearn: 0.1121711\ttotal: 14m 51s\tremaining: 8m 21s\n",
      "64:\tlearn: 0.1119194\ttotal: 15m 5s\tremaining: 8m 7s\n",
      "65:\tlearn: 0.1115621\ttotal: 15m 19s\tremaining: 7m 53s\n",
      "66:\tlearn: 0.1110767\ttotal: 15m 33s\tremaining: 7m 39s\n",
      "67:\tlearn: 0.1104844\ttotal: 15m 46s\tremaining: 7m 25s\n",
      "68:\tlearn: 0.1102297\ttotal: 16m\tremaining: 7m 11s\n",
      "69:\tlearn: 0.1096774\ttotal: 16m 14s\tremaining: 6m 57s\n",
      "70:\tlearn: 0.1094448\ttotal: 16m 28s\tremaining: 6m 43s\n",
      "71:\tlearn: 0.1092010\ttotal: 16m 42s\tremaining: 6m 29s\n",
      "72:\tlearn: 0.1090154\ttotal: 16m 56s\tremaining: 6m 15s\n",
      "73:\tlearn: 0.1082066\ttotal: 17m 10s\tremaining: 6m 1s\n",
      "74:\tlearn: 0.1080110\ttotal: 17m 24s\tremaining: 5m 48s\n",
      "75:\tlearn: 0.1072601\ttotal: 17m 39s\tremaining: 5m 34s\n",
      "76:\tlearn: 0.1070057\ttotal: 17m 53s\tremaining: 5m 20s\n",
      "77:\tlearn: 0.1065174\ttotal: 18m 7s\tremaining: 5m 6s\n",
      "78:\tlearn: 0.1062118\ttotal: 18m 21s\tremaining: 4m 52s\n",
      "79:\tlearn: 0.1053838\ttotal: 18m 34s\tremaining: 4m 38s\n",
      "80:\tlearn: 0.1051486\ttotal: 18m 48s\tremaining: 4m 24s\n",
      "81:\tlearn: 0.1049096\ttotal: 19m 2s\tremaining: 4m 10s\n",
      "82:\tlearn: 0.1047399\ttotal: 19m 16s\tremaining: 3m 56s\n",
      "83:\tlearn: 0.1040861\ttotal: 19m 30s\tremaining: 3m 43s\n",
      "84:\tlearn: 0.1037091\ttotal: 19m 44s\tremaining: 3m 29s\n",
      "85:\tlearn: 0.1031024\ttotal: 19m 58s\tremaining: 3m 15s\n",
      "86:\tlearn: 0.1028701\ttotal: 20m 12s\tremaining: 3m 1s\n",
      "87:\tlearn: 0.1026908\ttotal: 20m 26s\tremaining: 2m 47s\n",
      "88:\tlearn: 0.1025039\ttotal: 20m 40s\tremaining: 2m 33s\n",
      "89:\tlearn: 0.1019413\ttotal: 20m 54s\tremaining: 2m 19s\n",
      "90:\tlearn: 0.1016504\ttotal: 21m 8s\tremaining: 2m 5s\n",
      "91:\tlearn: 0.1008587\ttotal: 21m 22s\tremaining: 1m 51s\n",
      "92:\tlearn: 0.1006771\ttotal: 21m 36s\tremaining: 1m 37s\n",
      "93:\tlearn: 0.1001539\ttotal: 21m 50s\tremaining: 1m 23s\n",
      "94:\tlearn: 0.0999765\ttotal: 22m 4s\tremaining: 1m 9s\n",
      "95:\tlearn: 0.0995437\ttotal: 22m 18s\tremaining: 55.8s\n",
      "96:\tlearn: 0.0990420\ttotal: 22m 32s\tremaining: 41.8s\n",
      "97:\tlearn: 0.0986453\ttotal: 22m 46s\tremaining: 27.9s\n",
      "98:\tlearn: 0.0984186\ttotal: 23m\tremaining: 13.9s\n",
      "99:\tlearn: 0.0981284\ttotal: 23m 14s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3341969\ttotal: 13.6s\tremaining: 22m 27s\n",
      "1:\tlearn: 0.2466649\ttotal: 27.2s\tremaining: 22m 12s\n",
      "2:\tlearn: 0.2167687\ttotal: 40.4s\tremaining: 21m 47s\n",
      "3:\tlearn: 0.2020520\ttotal: 54s\tremaining: 21m 36s\n",
      "4:\tlearn: 0.1930994\ttotal: 1m 7s\tremaining: 21m 24s\n",
      "5:\tlearn: 0.1870084\ttotal: 1m 21s\tremaining: 21m 13s\n",
      "6:\tlearn: 0.1807552\ttotal: 1m 34s\tremaining: 20m 58s\n",
      "7:\tlearn: 0.1757180\ttotal: 1m 48s\tremaining: 20m 46s\n",
      "8:\tlearn: 0.1720252\ttotal: 2m 2s\tremaining: 20m 36s\n",
      "9:\tlearn: 0.1688386\ttotal: 2m 15s\tremaining: 20m 23s\n",
      "10:\tlearn: 0.1656075\ttotal: 2m 29s\tremaining: 20m 7s\n",
      "11:\tlearn: 0.1625899\ttotal: 2m 42s\tremaining: 19m 52s\n",
      "12:\tlearn: 0.1602148\ttotal: 2m 55s\tremaining: 19m 37s\n",
      "13:\tlearn: 0.1579229\ttotal: 3m 9s\tremaining: 19m 23s\n",
      "14:\tlearn: 0.1554287\ttotal: 3m 22s\tremaining: 19m 9s\n",
      "15:\tlearn: 0.1534545\ttotal: 3m 36s\tremaining: 18m 55s\n",
      "16:\tlearn: 0.1516930\ttotal: 3m 49s\tremaining: 18m 41s\n",
      "17:\tlearn: 0.1498484\ttotal: 4m 3s\tremaining: 18m 27s\n",
      "18:\tlearn: 0.1481075\ttotal: 4m 16s\tremaining: 18m 13s\n",
      "19:\tlearn: 0.1466155\ttotal: 4m 29s\tremaining: 17m 59s\n",
      "20:\tlearn: 0.1448565\ttotal: 4m 43s\tremaining: 17m 45s\n",
      "21:\tlearn: 0.1434759\ttotal: 4m 56s\tremaining: 17m 31s\n",
      "22:\tlearn: 0.1423362\ttotal: 5m 10s\tremaining: 17m 18s\n",
      "23:\tlearn: 0.1410451\ttotal: 5m 23s\tremaining: 17m 4s\n",
      "24:\tlearn: 0.1397537\ttotal: 5m 37s\tremaining: 16m 51s\n",
      "25:\tlearn: 0.1386952\ttotal: 5m 50s\tremaining: 16m 37s\n",
      "26:\tlearn: 0.1374727\ttotal: 6m 4s\tremaining: 16m 24s\n",
      "27:\tlearn: 0.1359684\ttotal: 6m 17s\tremaining: 16m 10s\n",
      "28:\tlearn: 0.1351545\ttotal: 6m 30s\tremaining: 15m 56s\n",
      "29:\tlearn: 0.1341255\ttotal: 6m 44s\tremaining: 15m 43s\n",
      "30:\tlearn: 0.1330349\ttotal: 6m 57s\tremaining: 15m 30s\n",
      "31:\tlearn: 0.1319629\ttotal: 7m 11s\tremaining: 15m 16s\n",
      "32:\tlearn: 0.1312359\ttotal: 7m 24s\tremaining: 15m 3s\n",
      "33:\tlearn: 0.1299640\ttotal: 7m 38s\tremaining: 14m 50s\n",
      "34:\tlearn: 0.1293803\ttotal: 7m 51s\tremaining: 14m 36s\n",
      "35:\tlearn: 0.1286339\ttotal: 8m 5s\tremaining: 14m 23s\n",
      "36:\tlearn: 0.1274943\ttotal: 8m 18s\tremaining: 14m 9s\n",
      "37:\tlearn: 0.1269874\ttotal: 8m 32s\tremaining: 13m 56s\n",
      "38:\tlearn: 0.1261492\ttotal: 8m 45s\tremaining: 13m 42s\n",
      "39:\tlearn: 0.1249583\ttotal: 8m 59s\tremaining: 13m 29s\n",
      "40:\tlearn: 0.1242487\ttotal: 9m 13s\tremaining: 13m 16s\n",
      "41:\tlearn: 0.1236651\ttotal: 9m 26s\tremaining: 13m 2s\n",
      "42:\tlearn: 0.1231751\ttotal: 9m 40s\tremaining: 12m 49s\n",
      "43:\tlearn: 0.1224645\ttotal: 9m 54s\tremaining: 12m 36s\n",
      "44:\tlearn: 0.1220503\ttotal: 10m 8s\tremaining: 12m 23s\n",
      "45:\tlearn: 0.1214657\ttotal: 10m 22s\tremaining: 12m 10s\n",
      "46:\tlearn: 0.1205524\ttotal: 10m 36s\tremaining: 11m 57s\n",
      "47:\tlearn: 0.1196146\ttotal: 10m 49s\tremaining: 11m 43s\n",
      "48:\tlearn: 0.1186776\ttotal: 11m 3s\tremaining: 11m 30s\n",
      "49:\tlearn: 0.1182623\ttotal: 11m 17s\tremaining: 11m 17s\n",
      "50:\tlearn: 0.1174960\ttotal: 11m 31s\tremaining: 11m 3s\n",
      "51:\tlearn: 0.1170993\ttotal: 11m 44s\tremaining: 10m 50s\n",
      "52:\tlearn: 0.1167162\ttotal: 11m 58s\tremaining: 10m 37s\n",
      "53:\tlearn: 0.1160237\ttotal: 12m 12s\tremaining: 10m 24s\n",
      "54:\tlearn: 0.1156748\ttotal: 12m 26s\tremaining: 10m 10s\n",
      "55:\tlearn: 0.1153230\ttotal: 12m 39s\tremaining: 9m 56s\n",
      "56:\tlearn: 0.1146560\ttotal: 12m 53s\tremaining: 9m 43s\n",
      "57:\tlearn: 0.1143167\ttotal: 13m 6s\tremaining: 9m 29s\n",
      "58:\tlearn: 0.1139950\ttotal: 13m 20s\tremaining: 9m 16s\n",
      "59:\tlearn: 0.1137129\ttotal: 13m 33s\tremaining: 9m 2s\n",
      "60:\tlearn: 0.1128971\ttotal: 13m 47s\tremaining: 8m 48s\n",
      "61:\tlearn: 0.1126201\ttotal: 14m 1s\tremaining: 8m 35s\n",
      "62:\tlearn: 0.1123057\ttotal: 14m 14s\tremaining: 8m 21s\n",
      "63:\tlearn: 0.1120496\ttotal: 14m 28s\tremaining: 8m 8s\n",
      "64:\tlearn: 0.1117876\ttotal: 14m 41s\tremaining: 7m 54s\n",
      "65:\tlearn: 0.1112633\ttotal: 14m 55s\tremaining: 7m 41s\n",
      "66:\tlearn: 0.1110210\ttotal: 15m 9s\tremaining: 7m 27s\n",
      "67:\tlearn: 0.1107383\ttotal: 15m 23s\tremaining: 7m 14s\n",
      "68:\tlearn: 0.1104092\ttotal: 15m 36s\tremaining: 7m\n",
      "69:\tlearn: 0.1097016\ttotal: 15m 50s\tremaining: 6m 47s\n",
      "70:\tlearn: 0.1092112\ttotal: 16m 4s\tremaining: 6m 33s\n",
      "71:\tlearn: 0.1089792\ttotal: 16m 18s\tremaining: 6m 20s\n",
      "72:\tlearn: 0.1087174\ttotal: 16m 32s\tremaining: 6m 7s\n",
      "73:\tlearn: 0.1081113\ttotal: 16m 45s\tremaining: 5m 53s\n",
      "74:\tlearn: 0.1073936\ttotal: 16m 59s\tremaining: 5m 39s\n",
      "75:\tlearn: 0.1069199\ttotal: 17m 12s\tremaining: 5m 26s\n",
      "76:\tlearn: 0.1064147\ttotal: 17m 26s\tremaining: 5m 12s\n",
      "77:\tlearn: 0.1060908\ttotal: 17m 39s\tremaining: 4m 58s\n",
      "78:\tlearn: 0.1058633\ttotal: 17m 53s\tremaining: 4m 45s\n",
      "79:\tlearn: 0.1052293\ttotal: 18m 7s\tremaining: 4m 31s\n",
      "80:\tlearn: 0.1050307\ttotal: 18m 20s\tremaining: 4m 18s\n",
      "81:\tlearn: 0.1045685\ttotal: 18m 34s\tremaining: 4m 4s\n",
      "82:\tlearn: 0.1039063\ttotal: 18m 49s\tremaining: 3m 51s\n",
      "83:\tlearn: 0.1032479\ttotal: 19m 3s\tremaining: 3m 37s\n",
      "84:\tlearn: 0.1030608\ttotal: 19m 16s\tremaining: 3m 24s\n",
      "85:\tlearn: 0.1025797\ttotal: 19m 30s\tremaining: 3m 10s\n",
      "86:\tlearn: 0.1023971\ttotal: 19m 44s\tremaining: 2m 56s\n",
      "87:\tlearn: 0.1017937\ttotal: 19m 57s\tremaining: 2m 43s\n",
      "88:\tlearn: 0.1015793\ttotal: 20m 11s\tremaining: 2m 29s\n",
      "89:\tlearn: 0.1013539\ttotal: 20m 25s\tremaining: 2m 16s\n",
      "90:\tlearn: 0.1006707\ttotal: 20m 38s\tremaining: 2m 2s\n",
      "91:\tlearn: 0.1004218\ttotal: 20m 52s\tremaining: 1m 48s\n",
      "92:\tlearn: 0.1002618\ttotal: 21m 5s\tremaining: 1m 35s\n",
      "93:\tlearn: 0.0996968\ttotal: 21m 19s\tremaining: 1m 21s\n",
      "94:\tlearn: 0.0994928\ttotal: 21m 33s\tremaining: 1m 8s\n",
      "95:\tlearn: 0.0991735\ttotal: 21m 46s\tremaining: 54.4s\n",
      "96:\tlearn: 0.0990149\ttotal: 22m\tremaining: 40.8s\n",
      "97:\tlearn: 0.0986872\ttotal: 22m 14s\tremaining: 27.2s\n",
      "98:\tlearn: 0.0980736\ttotal: 22m 27s\tremaining: 13.6s\n",
      "99:\tlearn: 0.0977170\ttotal: 22m 41s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3301795\ttotal: 14.2s\tremaining: 23m 22s\n",
      "1:\tlearn: 0.2448223\ttotal: 28.2s\tremaining: 22m 59s\n",
      "2:\tlearn: 0.2146204\ttotal: 42.1s\tremaining: 22m 42s\n",
      "3:\tlearn: 0.2001216\ttotal: 56.5s\tremaining: 22m 35s\n",
      "4:\tlearn: 0.1914283\ttotal: 1m 10s\tremaining: 22m 20s\n",
      "5:\tlearn: 0.1845098\ttotal: 1m 24s\tremaining: 22m 6s\n",
      "6:\tlearn: 0.1785134\ttotal: 1m 38s\tremaining: 21m 51s\n",
      "7:\tlearn: 0.1747217\ttotal: 1m 52s\tremaining: 21m 37s\n",
      "8:\tlearn: 0.1712881\ttotal: 2m 6s\tremaining: 21m 21s\n",
      "9:\tlearn: 0.1680876\ttotal: 2m 20s\tremaining: 21m 4s\n",
      "10:\tlearn: 0.1650894\ttotal: 2m 34s\tremaining: 20m 49s\n",
      "11:\tlearn: 0.1625834\ttotal: 2m 48s\tremaining: 20m 33s\n",
      "12:\tlearn: 0.1601195\ttotal: 3m 2s\tremaining: 20m 19s\n",
      "13:\tlearn: 0.1577518\ttotal: 3m 16s\tremaining: 20m 5s\n",
      "14:\tlearn: 0.1560460\ttotal: 3m 30s\tremaining: 19m 51s\n",
      "15:\tlearn: 0.1539242\ttotal: 3m 44s\tremaining: 19m 37s\n",
      "16:\tlearn: 0.1520694\ttotal: 3m 58s\tremaining: 19m 23s\n",
      "17:\tlearn: 0.1505512\ttotal: 4m 12s\tremaining: 19m 9s\n",
      "18:\tlearn: 0.1489875\ttotal: 4m 26s\tremaining: 18m 55s\n",
      "19:\tlearn: 0.1471054\ttotal: 4m 40s\tremaining: 18m 41s\n",
      "20:\tlearn: 0.1459740\ttotal: 4m 54s\tremaining: 18m 27s\n",
      "21:\tlearn: 0.1446110\ttotal: 5m 8s\tremaining: 18m 13s\n",
      "22:\tlearn: 0.1434389\ttotal: 5m 22s\tremaining: 17m 58s\n",
      "23:\tlearn: 0.1421016\ttotal: 5m 36s\tremaining: 17m 44s\n",
      "24:\tlearn: 0.1409766\ttotal: 5m 50s\tremaining: 17m 30s\n",
      "25:\tlearn: 0.1400870\ttotal: 6m 4s\tremaining: 17m 16s\n",
      "26:\tlearn: 0.1390347\ttotal: 6m 18s\tremaining: 17m 2s\n",
      "27:\tlearn: 0.1379310\ttotal: 6m 32s\tremaining: 16m 48s\n",
      "28:\tlearn: 0.1369414\ttotal: 6m 45s\tremaining: 16m 33s\n",
      "29:\tlearn: 0.1356952\ttotal: 6m 59s\tremaining: 16m 19s\n",
      "30:\tlearn: 0.1346543\ttotal: 7m 13s\tremaining: 16m 5s\n",
      "31:\tlearn: 0.1340531\ttotal: 7m 27s\tremaining: 15m 51s\n",
      "32:\tlearn: 0.1327932\ttotal: 7m 41s\tremaining: 15m 37s\n",
      "33:\tlearn: 0.1321084\ttotal: 7m 55s\tremaining: 15m 23s\n",
      "34:\tlearn: 0.1316095\ttotal: 8m 9s\tremaining: 15m 9s\n",
      "35:\tlearn: 0.1311049\ttotal: 8m 23s\tremaining: 14m 55s\n",
      "36:\tlearn: 0.1300280\ttotal: 8m 37s\tremaining: 14m 41s\n",
      "37:\tlearn: 0.1283549\ttotal: 8m 51s\tremaining: 14m 27s\n",
      "38:\tlearn: 0.1276173\ttotal: 9m 5s\tremaining: 14m 13s\n",
      "39:\tlearn: 0.1266065\ttotal: 9m 19s\tremaining: 13m 59s\n",
      "40:\tlearn: 0.1258003\ttotal: 9m 33s\tremaining: 13m 45s\n",
      "41:\tlearn: 0.1253210\ttotal: 9m 47s\tremaining: 13m 31s\n",
      "42:\tlearn: 0.1244014\ttotal: 10m 1s\tremaining: 13m 17s\n",
      "43:\tlearn: 0.1237655\ttotal: 10m 15s\tremaining: 13m 3s\n",
      "44:\tlearn: 0.1228957\ttotal: 10m 29s\tremaining: 12m 49s\n",
      "45:\tlearn: 0.1219779\ttotal: 10m 43s\tremaining: 12m 35s\n",
      "46:\tlearn: 0.1213150\ttotal: 10m 57s\tremaining: 12m 21s\n",
      "47:\tlearn: 0.1208466\ttotal: 11m 11s\tremaining: 12m 7s\n",
      "48:\tlearn: 0.1204452\ttotal: 11m 25s\tremaining: 11m 53s\n",
      "49:\tlearn: 0.1200720\ttotal: 11m 39s\tremaining: 11m 39s\n",
      "50:\tlearn: 0.1197185\ttotal: 11m 53s\tremaining: 11m 25s\n",
      "51:\tlearn: 0.1193693\ttotal: 12m 7s\tremaining: 11m 11s\n",
      "52:\tlearn: 0.1188178\ttotal: 12m 21s\tremaining: 10m 57s\n",
      "53:\tlearn: 0.1179832\ttotal: 12m 34s\tremaining: 10m 43s\n",
      "54:\tlearn: 0.1169130\ttotal: 12m 48s\tremaining: 10m 29s\n",
      "55:\tlearn: 0.1165854\ttotal: 13m 3s\tremaining: 10m 15s\n",
      "56:\tlearn: 0.1161920\ttotal: 13m 17s\tremaining: 10m 1s\n",
      "57:\tlearn: 0.1158391\ttotal: 13m 31s\tremaining: 9m 47s\n",
      "58:\tlearn: 0.1155375\ttotal: 13m 45s\tremaining: 9m 33s\n",
      "59:\tlearn: 0.1152449\ttotal: 13m 59s\tremaining: 9m 19s\n",
      "60:\tlearn: 0.1144094\ttotal: 14m 13s\tremaining: 9m 5s\n",
      "61:\tlearn: 0.1141316\ttotal: 14m 27s\tremaining: 8m 51s\n",
      "62:\tlearn: 0.1138709\ttotal: 14m 41s\tremaining: 8m 37s\n",
      "63:\tlearn: 0.1133661\ttotal: 14m 55s\tremaining: 8m 23s\n",
      "64:\tlearn: 0.1127458\ttotal: 15m 9s\tremaining: 8m 9s\n",
      "65:\tlearn: 0.1124741\ttotal: 15m 23s\tremaining: 7m 55s\n",
      "66:\tlearn: 0.1119713\ttotal: 15m 37s\tremaining: 7m 41s\n",
      "67:\tlearn: 0.1113670\ttotal: 15m 51s\tremaining: 7m 27s\n",
      "68:\tlearn: 0.1107051\ttotal: 16m 5s\tremaining: 7m 13s\n",
      "69:\tlearn: 0.1104152\ttotal: 16m 19s\tremaining: 6m 59s\n",
      "70:\tlearn: 0.1097606\ttotal: 16m 33s\tremaining: 6m 45s\n",
      "71:\tlearn: 0.1092349\ttotal: 16m 47s\tremaining: 6m 31s\n",
      "72:\tlearn: 0.1088986\ttotal: 17m 1s\tremaining: 6m 17s\n",
      "73:\tlearn: 0.1086687\ttotal: 17m 14s\tremaining: 6m 3s\n",
      "74:\tlearn: 0.1080286\ttotal: 17m 29s\tremaining: 5m 49s\n",
      "75:\tlearn: 0.1078051\ttotal: 17m 43s\tremaining: 5m 35s\n",
      "76:\tlearn: 0.1072497\ttotal: 17m 57s\tremaining: 5m 21s\n",
      "77:\tlearn: 0.1069015\ttotal: 18m 11s\tremaining: 5m 7s\n",
      "78:\tlearn: 0.1067061\ttotal: 18m 25s\tremaining: 4m 53s\n",
      "79:\tlearn: 0.1061801\ttotal: 18m 38s\tremaining: 4m 39s\n",
      "80:\tlearn: 0.1059206\ttotal: 18m 52s\tremaining: 4m 25s\n",
      "81:\tlearn: 0.1051618\ttotal: 19m 6s\tremaining: 4m 11s\n",
      "82:\tlearn: 0.1044744\ttotal: 19m 20s\tremaining: 3m 57s\n",
      "83:\tlearn: 0.1042691\ttotal: 19m 35s\tremaining: 3m 43s\n",
      "84:\tlearn: 0.1036129\ttotal: 19m 49s\tremaining: 3m 29s\n",
      "85:\tlearn: 0.1034210\ttotal: 20m 3s\tremaining: 3m 15s\n",
      "86:\tlearn: 0.1031541\ttotal: 20m 17s\tremaining: 3m 1s\n",
      "87:\tlearn: 0.1029830\ttotal: 20m 31s\tremaining: 2m 47s\n",
      "88:\tlearn: 0.1027575\ttotal: 20m 45s\tremaining: 2m 33s\n",
      "89:\tlearn: 0.1025367\ttotal: 20m 59s\tremaining: 2m 19s\n",
      "90:\tlearn: 0.1020669\ttotal: 21m 13s\tremaining: 2m 5s\n",
      "91:\tlearn: 0.1019004\ttotal: 21m 27s\tremaining: 1m 51s\n",
      "92:\tlearn: 0.1015267\ttotal: 21m 41s\tremaining: 1m 37s\n",
      "93:\tlearn: 0.1013432\ttotal: 21m 55s\tremaining: 1m 23s\n",
      "94:\tlearn: 0.1008772\ttotal: 22m 9s\tremaining: 1m 9s\n",
      "95:\tlearn: 0.1006275\ttotal: 22m 23s\tremaining: 56s\n",
      "96:\tlearn: 0.1003396\ttotal: 22m 37s\tremaining: 42s\n",
      "97:\tlearn: 0.0998599\ttotal: 22m 51s\tremaining: 28s\n",
      "98:\tlearn: 0.0994740\ttotal: 23m 5s\tremaining: 14s\n",
      "99:\tlearn: 0.0989973\ttotal: 23m 19s\tremaining: 0us\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3323961\ttotal: 16.9s\tremaining: 27m 49s\n",
      "1:\tlearn: 0.2425564\ttotal: 33.2s\tremaining: 27m 8s\n",
      "2:\tlearn: 0.2140628\ttotal: 49.4s\tremaining: 26m 37s\n",
      "3:\tlearn: 0.2010850\ttotal: 1m 5s\tremaining: 26m 23s\n",
      "4:\tlearn: 0.1921287\ttotal: 1m 22s\tremaining: 26m 7s\n",
      "5:\tlearn: 0.1860960\ttotal: 1m 38s\tremaining: 25m 47s\n",
      "6:\tlearn: 0.1800690\ttotal: 1m 54s\tremaining: 25m 25s\n",
      "7:\tlearn: 0.1762590\ttotal: 2m 11s\tremaining: 25m 7s\n",
      "8:\tlearn: 0.1723721\ttotal: 2m 27s\tremaining: 24m 52s\n",
      "9:\tlearn: 0.1690962\ttotal: 2m 43s\tremaining: 24m 33s\n",
      "10:\tlearn: 0.1663323\ttotal: 3m\tremaining: 24m 17s\n",
      "11:\tlearn: 0.1635600\ttotal: 3m 16s\tremaining: 24m 1s\n",
      "12:\tlearn: 0.1602025\ttotal: 3m 32s\tremaining: 23m 45s\n",
      "13:\tlearn: 0.1581348\ttotal: 3m 49s\tremaining: 23m 29s\n",
      "14:\tlearn: 0.1560909\ttotal: 4m 6s\tremaining: 23m 14s\n",
      "15:\tlearn: 0.1545419\ttotal: 4m 22s\tremaining: 22m 58s\n",
      "16:\tlearn: 0.1522024\ttotal: 4m 39s\tremaining: 22m 42s\n",
      "17:\tlearn: 0.1500971\ttotal: 4m 55s\tremaining: 22m 25s\n",
      "18:\tlearn: 0.1487496\ttotal: 5m 11s\tremaining: 22m 9s\n",
      "19:\tlearn: 0.1469820\ttotal: 5m 28s\tremaining: 21m 52s\n",
      "20:\tlearn: 0.1457412\ttotal: 5m 44s\tremaining: 21m 36s\n",
      "21:\tlearn: 0.1445097\ttotal: 6m 1s\tremaining: 21m 20s\n",
      "22:\tlearn: 0.1432797\ttotal: 6m 17s\tremaining: 21m 3s\n",
      "23:\tlearn: 0.1420675\ttotal: 6m 33s\tremaining: 20m 47s\n",
      "24:\tlearn: 0.1409050\ttotal: 6m 50s\tremaining: 20m 31s\n",
      "25:\tlearn: 0.1398973\ttotal: 7m 7s\tremaining: 20m 15s\n",
      "26:\tlearn: 0.1388964\ttotal: 7m 23s\tremaining: 19m 59s\n",
      "27:\tlearn: 0.1377764\ttotal: 7m 40s\tremaining: 19m 43s\n",
      "28:\tlearn: 0.1370520\ttotal: 7m 56s\tremaining: 19m 27s\n",
      "29:\tlearn: 0.1353615\ttotal: 8m 13s\tremaining: 19m 10s\n",
      "30:\tlearn: 0.1344080\ttotal: 8m 29s\tremaining: 18m 55s\n",
      "31:\tlearn: 0.1332977\ttotal: 8m 46s\tremaining: 18m 38s\n",
      "32:\tlearn: 0.1327082\ttotal: 9m 3s\tremaining: 18m 22s\n",
      "33:\tlearn: 0.1319681\ttotal: 9m 19s\tremaining: 18m 6s\n",
      "34:\tlearn: 0.1308292\ttotal: 9m 36s\tremaining: 17m 49s\n",
      "35:\tlearn: 0.1296822\ttotal: 9m 52s\tremaining: 17m 33s\n",
      "36:\tlearn: 0.1291895\ttotal: 10m 9s\tremaining: 17m 17s\n",
      "37:\tlearn: 0.1278030\ttotal: 10m 25s\tremaining: 17m\n",
      "38:\tlearn: 0.1273187\ttotal: 10m 41s\tremaining: 16m 43s\n",
      "39:\tlearn: 0.1268863\ttotal: 10m 58s\tremaining: 16m 27s\n",
      "40:\tlearn: 0.1260693\ttotal: 11m 15s\tremaining: 16m 12s\n",
      "41:\tlearn: 0.1250367\ttotal: 11m 32s\tremaining: 15m 55s\n",
      "42:\tlearn: 0.1240153\ttotal: 11m 48s\tremaining: 15m 39s\n",
      "43:\tlearn: 0.1233508\ttotal: 12m 4s\tremaining: 15m 22s\n",
      "44:\tlearn: 0.1229480\ttotal: 12m 21s\tremaining: 15m 6s\n",
      "45:\tlearn: 0.1221603\ttotal: 12m 37s\tremaining: 14m 49s\n",
      "46:\tlearn: 0.1216450\ttotal: 12m 54s\tremaining: 14m 32s\n",
      "47:\tlearn: 0.1212801\ttotal: 13m 11s\tremaining: 14m 17s\n",
      "48:\tlearn: 0.1206855\ttotal: 13m 27s\tremaining: 14m\n",
      "49:\tlearn: 0.1201215\ttotal: 13m 43s\tremaining: 13m 43s\n",
      "50:\tlearn: 0.1191967\ttotal: 14m\tremaining: 13m 27s\n",
      "51:\tlearn: 0.1188265\ttotal: 14m 16s\tremaining: 13m 10s\n",
      "52:\tlearn: 0.1179308\ttotal: 14m 32s\tremaining: 12m 53s\n",
      "53:\tlearn: 0.1172462\ttotal: 14m 49s\tremaining: 12m 37s\n",
      "54:\tlearn: 0.1166881\ttotal: 15m 5s\tremaining: 12m 21s\n",
      "55:\tlearn: 0.1158810\ttotal: 15m 22s\tremaining: 12m 4s\n",
      "56:\tlearn: 0.1155546\ttotal: 15m 38s\tremaining: 11m 47s\n",
      "57:\tlearn: 0.1152529\ttotal: 15m 54s\tremaining: 11m 31s\n",
      "58:\tlearn: 0.1149728\ttotal: 16m 10s\tremaining: 11m 14s\n",
      "59:\tlearn: 0.1143329\ttotal: 16m 27s\tremaining: 10m 58s\n",
      "60:\tlearn: 0.1137068\ttotal: 16m 43s\tremaining: 10m 41s\n",
      "61:\tlearn: 0.1134152\ttotal: 17m\tremaining: 10m 25s\n",
      "62:\tlearn: 0.1131302\ttotal: 17m 16s\tremaining: 10m 8s\n",
      "63:\tlearn: 0.1125821\ttotal: 17m 32s\tremaining: 9m 52s\n",
      "64:\tlearn: 0.1123191\ttotal: 17m 49s\tremaining: 9m 35s\n",
      "65:\tlearn: 0.1120560\ttotal: 18m 5s\tremaining: 9m 19s\n",
      "66:\tlearn: 0.1118148\ttotal: 18m 22s\tremaining: 9m 2s\n",
      "67:\tlearn: 0.1115040\ttotal: 18m 38s\tremaining: 8m 46s\n",
      "68:\tlearn: 0.1108660\ttotal: 18m 54s\tremaining: 8m 29s\n",
      "69:\tlearn: 0.1102105\ttotal: 19m 10s\tremaining: 8m 13s\n",
      "70:\tlearn: 0.1099783\ttotal: 19m 27s\tremaining: 7m 56s\n",
      "71:\tlearn: 0.1096311\ttotal: 19m 44s\tremaining: 7m 40s\n",
      "72:\tlearn: 0.1091755\ttotal: 20m\tremaining: 7m 23s\n",
      "73:\tlearn: 0.1089555\ttotal: 20m 16s\tremaining: 7m 7s\n",
      "74:\tlearn: 0.1083136\ttotal: 20m 32s\tremaining: 6m 50s\n",
      "75:\tlearn: 0.1081188\ttotal: 20m 49s\tremaining: 6m 34s\n",
      "76:\tlearn: 0.1075737\ttotal: 21m 5s\tremaining: 6m 18s\n",
      "77:\tlearn: 0.1073637\ttotal: 21m 22s\tremaining: 6m 1s\n",
      "78:\tlearn: 0.1071826\ttotal: 21m 38s\tremaining: 5m 45s\n",
      "79:\tlearn: 0.1068769\ttotal: 21m 55s\tremaining: 5m 28s\n",
      "80:\tlearn: 0.1065676\ttotal: 22m 12s\tremaining: 5m 12s\n",
      "81:\tlearn: 0.1059831\ttotal: 22m 28s\tremaining: 4m 55s\n",
      "82:\tlearn: 0.1057978\ttotal: 22m 44s\tremaining: 4m 39s\n",
      "83:\tlearn: 0.1054890\ttotal: 23m\tremaining: 4m 22s\n",
      "84:\tlearn: 0.1050071\ttotal: 23m 16s\tremaining: 4m 6s\n",
      "85:\tlearn: 0.1047940\ttotal: 23m 32s\tremaining: 3m 50s\n",
      "86:\tlearn: 0.1046208\ttotal: 23m 49s\tremaining: 3m 33s\n",
      "87:\tlearn: 0.1044383\ttotal: 24m 5s\tremaining: 3m 17s\n",
      "88:\tlearn: 0.1039469\ttotal: 24m 21s\tremaining: 3m\n",
      "89:\tlearn: 0.1037940\ttotal: 24m 38s\tremaining: 2m 44s\n",
      "90:\tlearn: 0.1030893\ttotal: 24m 53s\tremaining: 2m 27s\n",
      "91:\tlearn: 0.1029347\ttotal: 25m 10s\tremaining: 2m 11s\n",
      "92:\tlearn: 0.1024768\ttotal: 25m 26s\tremaining: 1m 54s\n",
      "93:\tlearn: 0.1023359\ttotal: 25m 43s\tremaining: 1m 38s\n",
      "94:\tlearn: 0.1019165\ttotal: 25m 59s\tremaining: 1m 22s\n",
      "95:\tlearn: 0.1016638\ttotal: 26m 15s\tremaining: 1m 5s\n",
      "96:\tlearn: 0.1013701\ttotal: 26m 31s\tremaining: 49.2s\n",
      "97:\tlearn: 0.1010712\ttotal: 26m 47s\tremaining: 32.8s\n",
      "98:\tlearn: 0.1008752\ttotal: 27m 4s\tremaining: 16.4s\n",
      "99:\tlearn: 0.1007321\ttotal: 27m 20s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=<catboost.core.CatBoostClassifier object at 0x7fbb1034d820>,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'iterations': [10, 100],\n",
       "                                        'max_depth': [10, 20]},\n",
       "                   random_state=42, scoring='f1')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# инициализируем модель\n",
    "cat_model = CatBoostClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "# создаём словарь со значениями гиперпараметров для перебора\n",
    "cat_parameters = {\n",
    "        'iterations': [10, 100],\n",
    "        'max_depth': [10, 20]\n",
    "    }\n",
    " \n",
    "\n",
    "cat_search = RandomizedSearchCV(\n",
    "    cat_model,\n",
    "    cat_parameters,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "cat_search.fit(train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 при кросс-валидации: 0.753\n",
      "Параметры для лучшей модели: {'max_depth': 10, 'iterations': 100}\n"
     ]
    }
   ],
   "source": [
    "cat_f1 = np.round(cat_search.best_score_, 3)\n",
    "print(f'Метрика F1 при кросс-валидации: {cat_f1}')\n",
    "print(f'Параметры для лучшей модели: {cat_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model     F1\n",
       "0    LogisticRegression  0.751\n",
       "1  KNeighborsClassifier  0.307\n",
       "2    CatBoostClassifier  0.753"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_results = pd.DataFrame({'model': ['LogisticRegression', 'KNeighborsClassifier', 'CatBoostClassifier'], \n",
    "  'F1': [log_f1, kneighbors_f1, cat_f1]})\n",
    "\n",
    "models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшей моделью является CatBoostClassifier с гиперпараметрами: max_depth = 10, iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование лучшей модели\n",
    "Выполним предсказание на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 на тестовой выборке: 0.76\n"
     ]
    }
   ],
   "source": [
    "y_pred_cat = cat_search.predict(test_tfidf)\n",
    "print(f'Метрика F1 на тестовой выборке: {np.round(f1_score(y_test, y_pred_cat), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат укладывается в заданное нам условие: метрика F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "Нашей целью было обучить модель классифицировать комментарии на позитивные и негативные.\n",
    "\n",
    "Датасет был представлен 159292 комментариями. Из них 10.16% негативные, 89.84% позитивные.\n",
    "\n",
    "Мы провели следующую подготовку данных:\n",
    "* Удалили из текста лищние символы (пунктуация, лишние пробелы)\n",
    "* Провели лемматизацию слов с помощью SpaCy\n",
    "* Удалили стоп-слова\n",
    "* Провели векторизацию корпусов с помощью TfidfVectorizer\n",
    "\n",
    "Обучили три модели, подобрав им гиперпараметры:\n",
    "* LogisticRegression()\n",
    "* KNeighborsClassifier()\n",
    "* CatBoostClassifier()\n",
    "\n",
    "Лучшей моделью является CatBoostClassifier с гиперпараметрами: max_depth = 10, iterations = 100\n",
    "\n",
    "Метрика F1 лучшей модели на тестовой выборке 0.76, что укладывается в заданное нам условие."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 3537,
    "start_time": "2024-02-01T06:44:58.373Z"
   },
   {
    "duration": 2523,
    "start_time": "2024-02-01T06:46:49.112Z"
   },
   {
    "duration": 19,
    "start_time": "2024-02-01T06:47:02.767Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-01T06:47:53.116Z"
   },
   {
    "duration": 1052,
    "start_time": "2024-02-01T06:50:09.363Z"
   },
   {
    "duration": 8,
    "start_time": "2024-02-01T06:50:11.842Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-01T06:50:20.455Z"
   },
   {
    "duration": 9,
    "start_time": "2024-02-01T06:51:48.004Z"
   },
   {
    "duration": 134,
    "start_time": "2024-02-01T06:52:33.903Z"
   },
   {
    "duration": 84,
    "start_time": "2024-02-01T06:52:44.727Z"
   },
   {
    "duration": 219,
    "start_time": "2024-02-01T06:54:48.381Z"
   },
   {
    "duration": 328,
    "start_time": "2024-02-01T06:54:59.132Z"
   },
   {
    "duration": 101,
    "start_time": "2024-02-01T06:55:03.687Z"
   },
   {
    "duration": 85,
    "start_time": "2024-02-01T06:55:43.394Z"
   },
   {
    "duration": 91,
    "start_time": "2024-02-01T07:15:34.897Z"
   },
   {
    "duration": 8,
    "start_time": "2024-02-01T07:18:36.998Z"
   },
   {
    "duration": 99,
    "start_time": "2024-02-01T07:24:35.433Z"
   },
   {
    "duration": 20813,
    "start_time": "2024-02-01T07:25:05.932Z"
   },
   {
    "duration": 8,
    "start_time": "2024-02-01T07:35:21.503Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-01T07:36:49.959Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-01T07:40:48.433Z"
   },
   {
    "duration": 14835,
    "start_time": "2024-02-05T05:26:58.701Z"
   },
   {
    "duration": 3525,
    "start_time": "2024-02-05T05:27:19.632Z"
   },
   {
    "duration": 3212,
    "start_time": "2024-02-05T05:27:42.015Z"
   },
   {
    "duration": 13,
    "start_time": "2024-02-05T05:27:48.113Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-05T05:27:51.206Z"
   },
   {
    "duration": 102,
    "start_time": "2024-02-05T05:27:53.639Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-05T05:27:56.228Z"
   },
   {
    "duration": 205,
    "start_time": "2024-02-05T05:27:58.242Z"
   },
   {
    "duration": 13,
    "start_time": "2024-02-05T05:29:16.652Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-05T05:29:21.081Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-05T05:29:22.831Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-05T05:29:30.636Z"
   },
   {
    "duration": 617,
    "start_time": "2024-02-05T05:29:34.884Z"
   },
   {
    "duration": 2300,
    "start_time": "2024-02-05T05:29:39.068Z"
   },
   {
    "duration": 14,
    "start_time": "2024-02-05T05:31:49.038Z"
   },
   {
    "duration": 6,
    "start_time": "2024-02-05T05:32:33.911Z"
   },
   {
    "duration": 13,
    "start_time": "2024-02-05T05:32:37.543Z"
   },
   {
    "duration": 2372536,
    "start_time": "2024-02-05T05:32:47.040Z"
   },
   {
    "duration": 64,
    "start_time": "2024-02-05T06:13:00.658Z"
   },
   {
    "duration": 6,
    "start_time": "2024-02-05T07:43:12.851Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-05T07:52:17.437Z"
   },
   {
    "duration": 21,
    "start_time": "2024-02-05T07:54:01.908Z"
   },
   {
    "duration": 77,
    "start_time": "2024-02-05T07:54:05.363Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-05T07:54:07.323Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-05T07:54:22.384Z"
   },
   {
    "duration": 8562,
    "start_time": "2024-02-05T07:59:07.366Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-05T08:00:02.909Z"
   },
   {
    "duration": 20,
    "start_time": "2024-02-05T09:45:10.960Z"
   },
   {
    "duration": 9728,
    "start_time": "2024-02-05T09:45:45.473Z"
   },
   {
    "duration": 3430,
    "start_time": "2024-02-05T09:45:55.203Z"
   },
   {
    "duration": 954,
    "start_time": "2024-02-05T09:45:58.635Z"
   },
   {
    "duration": 11,
    "start_time": "2024-02-05T09:45:59.591Z"
   },
   {
    "duration": 12,
    "start_time": "2024-02-05T09:45:59.604Z"
   },
   {
    "duration": 110,
    "start_time": "2024-02-05T09:45:59.618Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-05T09:45:59.730Z"
   },
   {
    "duration": 550,
    "start_time": "2024-02-05T09:45:59.735Z"
   },
   {
    "duration": 2333,
    "start_time": "2024-02-05T09:46:00.287Z"
   },
   {
    "duration": 2416193,
    "start_time": "2024-02-05T09:46:02.622Z"
   },
   {
    "duration": 80,
    "start_time": "2024-02-05T10:26:18.816Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-05T10:26:18.898Z"
   },
   {
    "duration": 59,
    "start_time": "2024-02-05T10:26:18.903Z"
   },
   {
    "duration": 8258,
    "start_time": "2024-02-05T10:26:18.964Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-05T10:26:27.224Z"
   },
   {
    "duration": 203,
    "start_time": "2024-02-05T10:26:27.229Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-05T10:42:35.676Z"
   },
   {
    "duration": 24,
    "start_time": "2024-02-05T11:27:34.627Z"
   },
   {
    "duration": 190,
    "start_time": "2024-02-05T11:27:46.508Z"
   },
   {
    "duration": 14,
    "start_time": "2024-02-05T11:28:12.619Z"
   },
   {
    "duration": 184,
    "start_time": "2024-02-05T11:28:46.771Z"
   },
   {
    "duration": 137,
    "start_time": "2024-02-05T11:30:27.368Z"
   },
   {
    "duration": 363,
    "start_time": "2024-02-05T11:31:00.302Z"
   },
   {
    "duration": 379342,
    "start_time": "2024-02-05T11:31:38.431Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-05T12:11:23.245Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-05T12:40:16.910Z"
   },
   {
    "duration": 10333825,
    "start_time": "2024-02-05T12:48:26.956Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-05T15:40:40.784Z"
   },
   {
    "duration": 22,
    "start_time": "2024-02-05T15:40:40.790Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-05T15:40:40.814Z"
   },
   {
    "duration": 6,
    "start_time": "2024-02-05T15:40:56.436Z"
   },
   {
    "duration": 9425,
    "start_time": "2024-02-06T01:08:56.295Z"
   },
   {
    "duration": 3381,
    "start_time": "2024-02-06T01:10:05.499Z"
   },
   {
    "duration": 951,
    "start_time": "2024-02-06T01:10:29.414Z"
   },
   {
    "duration": 13,
    "start_time": "2024-02-06T01:10:31.527Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-06T01:10:33.807Z"
   },
   {
    "duration": 99,
    "start_time": "2024-02-06T01:10:35.450Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-06T01:10:38.493Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-06T01:10:40.234Z"
   },
   {
    "duration": 9098,
    "start_time": "2024-02-06T01:10:50.243Z"
   },
   {
    "duration": 3386,
    "start_time": "2024-02-06T01:11:12.289Z"
   },
   {
    "duration": 890,
    "start_time": "2024-02-06T01:11:20.220Z"
   },
   {
    "duration": 12,
    "start_time": "2024-02-06T01:11:22.861Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-06T01:11:27.709Z"
   },
   {
    "duration": 98,
    "start_time": "2024-02-06T01:11:30.349Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-06T01:11:33.611Z"
   },
   {
    "duration": 494,
    "start_time": "2024-02-06T01:11:36.201Z"
   },
   {
    "duration": 2298,
    "start_time": "2024-02-06T01:11:41.409Z"
   },
   {
    "duration": 2296978,
    "start_time": "2024-02-06T01:11:46.547Z"
   },
   {
    "duration": 62,
    "start_time": "2024-02-06T01:50:11.682Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-06T01:50:14.806Z"
   },
   {
    "duration": 43,
    "start_time": "2024-02-06T01:50:18.358Z"
   },
   {
    "duration": 8055,
    "start_time": "2024-02-06T01:50:21.651Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-06T01:50:37.454Z"
   },
   {
    "duration": 379277,
    "start_time": "2024-02-06T01:50:43.097Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-06T01:58:03.530Z"
   },
   {
    "duration": 29,
    "start_time": "2024-02-06T01:58:11.163Z"
   },
   {
    "duration": 197,
    "start_time": "2024-02-06T02:03:45.499Z"
   },
   {
    "duration": 19,
    "start_time": "2024-02-06T02:03:54.831Z"
   },
   {
    "duration": 1172819,
    "start_time": "2024-02-06T02:04:09.277Z"
   },
   {
    "duration": 11,
    "start_time": "2024-02-06T02:23:47.856Z"
   },
   {
    "duration": 2,
    "start_time": "2024-02-06T02:23:53.868Z"
   },
   {
    "duration": 159559,
    "start_time": "2024-02-06T02:23:59.614Z"
   },
   {
    "duration": 10406293,
    "start_time": "2024-02-06T02:27:16.023Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-06T05:20:42.319Z"
   },
   {
    "duration": 445,
    "start_time": "2024-02-06T05:20:42.324Z"
   },
   {
    "duration": 103,
    "start_time": "2024-02-07T06:31:31.110Z"
   },
   {
    "duration": 15519,
    "start_time": "2024-02-07T06:36:37.563Z"
   },
   {
    "duration": 2724,
    "start_time": "2024-02-07T06:36:53.084Z"
   },
   {
    "duration": 3332,
    "start_time": "2024-02-07T06:36:55.810Z"
   },
   {
    "duration": 11,
    "start_time": "2024-02-07T06:36:59.143Z"
   },
   {
    "duration": 8,
    "start_time": "2024-02-07T06:36:59.156Z"
   },
   {
    "duration": 97,
    "start_time": "2024-02-07T06:36:59.165Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-07T06:36:59.263Z"
   },
   {
    "duration": 2092,
    "start_time": "2024-02-07T06:36:59.268Z"
   },
   {
    "duration": 490,
    "start_time": "2024-02-07T06:37:01.361Z"
   },
   {
    "duration": 2220391,
    "start_time": "2024-02-07T06:37:01.852Z"
   },
   {
    "duration": 84,
    "start_time": "2024-02-07T07:14:02.244Z"
   },
   {
    "duration": 2,
    "start_time": "2024-02-07T07:14:02.330Z"
   },
   {
    "duration": 211,
    "start_time": "2024-02-07T07:14:02.334Z"
   },
   {
    "duration": 7530,
    "start_time": "2024-02-07T07:14:02.548Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-07T07:14:10.079Z"
   },
   {
    "duration": 388777,
    "start_time": "2024-02-07T07:14:10.084Z"
   },
   {
    "duration": 92,
    "start_time": "2024-02-07T07:20:38.868Z"
   },
   {
    "duration": 186,
    "start_time": "2024-02-07T07:20:38.962Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-07T07:20:39.158Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-07T07:20:39.160Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-07T07:20:39.161Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-07T07:20:39.163Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-07T07:20:39.164Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-07T07:21:00.757Z"
   },
   {
    "duration": 1098822,
    "start_time": "2024-02-07T07:21:19.330Z"
   },
   {
    "duration": 14,
    "start_time": "2024-02-07T07:39:38.158Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-07T07:39:38.173Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-07T07:39:38.175Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-07T07:39:38.176Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-07T07:39:38.177Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-07T07:40:54.895Z"
   },
   {
    "duration": 9559558,
    "start_time": "2024-02-07T07:41:02.482Z"
   },
   {
    "duration": 7,
    "start_time": "2024-02-07T10:20:22.045Z"
   },
   {
    "duration": 100,
    "start_time": "2024-02-07T10:20:22.054Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-07T10:20:22.155Z"
   },
   {
    "duration": 10,
    "start_time": "2024-02-07T10:38:59.932Z"
   },
   {
    "duration": 418,
    "start_time": "2024-02-07T10:39:47.923Z"
   },
   {
    "duration": 401,
    "start_time": "2024-02-07T10:40:14.747Z"
   },
   {
    "duration": 20636,
    "start_time": "2024-02-07T13:19:24.139Z"
   },
   {
    "duration": 5167,
    "start_time": "2024-02-07T13:19:44.777Z"
   },
   {
    "duration": 2176,
    "start_time": "2024-02-07T13:19:49.946Z"
   },
   {
    "duration": 10,
    "start_time": "2024-02-07T13:19:52.123Z"
   },
   {
    "duration": 25,
    "start_time": "2024-02-07T13:19:52.135Z"
   },
   {
    "duration": 142,
    "start_time": "2024-02-07T13:19:52.162Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-07T13:19:52.306Z"
   },
   {
    "duration": 2082,
    "start_time": "2024-02-07T13:19:52.310Z"
   },
   {
    "duration": 460,
    "start_time": "2024-02-07T13:19:54.393Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
